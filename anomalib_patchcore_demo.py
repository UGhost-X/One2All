import os
# è®¾ç½®Hugging Face Hubå›½å†…é•œåƒ
os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"
import shutil
import numpy as np
import cv2  # å¼•å…¥OpenCVç”¨æ¥åšæ¨¡ç³Šï¼Œæ¨¡æ‹ŸçœŸå®çº¹ç†
from PIL import Image
from pathlib import Path
from anomalib.data import Folder
from anomalib.models import Patchcore
from anomalib.engine import Engine

def prepare_data(base_path: Path):
    """
    æ”¹è¿›çš„æ•°æ®ç”Ÿæˆï¼šæ¨¡æ‹Ÿå·¥ä¸šè¡¨é¢çš„â€œçº¹ç†â€
    PatchCore éœ€è¦ç‰¹å¾æå–ï¼Œçº¯æ¸å˜å›¾æ— æ³•æå–æœ‰æ•ˆç‰¹å¾ã€‚
    """
    print(f"æ­£åœ¨æ¸…ç†å¹¶å‡†å¤‡æ¨¡æ‹Ÿæ•°æ®: {base_path}...")
    if base_path.exists():
        shutil.rmtree(base_path)
    
    train_good = base_path / "train" / "good"
    test_good = base_path / "test" / "good"
    test_bad = base_path / "test" / "bad"
    
    for path in [train_good, test_good, test_bad]:
        path.mkdir(parents=True, exist_ok=True)
    
    def generate_textured_image(seed, defect=False):
        np.random.seed(seed)
        size = 256
        base_noise = np.random.normal(128, 30, (size, size)).astype(np.uint8)
        texture = cv2.GaussianBlur(base_noise, (5, 5), 0)
        
        # è½¬æˆ3é€šé“
        img = cv2.cvtColor(texture, cv2.COLOR_GRAY2RGB)
        
        if defect:
            if np.random.rand() > 0.5:
                cv2.line(img, (50, 50), (150, 150), (0, 0, 0), thickness=3)
            # ç¼ºé™·2: æ±¡æ¸ (é¢œè‰²å—)
            else:
                cv2.circle(img, (128, 128), 30, (255, 50, 50), thickness=-1)
                
        return img
    
    # ç”Ÿæˆè®­ç»ƒæ•°æ® (å¢åŠ åˆ°30å¼ ï¼Œè¦†ç›–çº¹ç†çš„éšæœºæ€§)
    for i in range(30):
        img = generate_textured_image(i, defect=False)
        Image.fromarray(img).save(train_good / f"{i}.png")
    
    # ç”Ÿæˆæµ‹è¯•æ­£å¸¸æ•°æ®
    for i in range(10):
        img = generate_textured_image(100 + i, defect=False)
        Image.fromarray(img).save(test_good / f"{i}.png")
    
    # ç”Ÿæˆå¼‚å¸¸æ•°æ®
    for i in range(10):
        img = generate_textured_image(200 + i, defect=True)
        Image.fromarray(img).save(test_bad / f"{i}.png")

def run_demo():
    # --- å…³é”®é…ç½®ä¿®æ”¹ ---
    CONFIG = {
        "model": {
            "backbone": "resnet18", 
            "layers": ["layer2", "layer3"],
            "coreset_sampling_ratio": 0.1,
        },
        "dataset": {
            "image_size": (256, 256),
            "train_batch_size": 4,
            "eval_batch_size": 4,
        },
        "engine": {
            "max_epochs": 1,
            "default_root_dir": "./results_patchcore_optimized",
        }
    }

    # 1. å‡†å¤‡æ•°æ®
    data_root = Path("./datasets/dummy_texture")
    prepare_data(data_root)
    
    # 2. æ•°æ®æ¨¡å—
    datamodule = Folder(
        name="dummy_texture",
        root=data_root,
        normal_dir="train/good",
        abnormal_dir="test/bad",
        normal_test_dir="test/good",
        train_batch_size=CONFIG["dataset"]["train_batch_size"],
        eval_batch_size=CONFIG["dataset"]["eval_batch_size"],
        num_workers=4,
    )

    # 3. æ¨¡å‹
    model = Patchcore(
        backbone=CONFIG["model"]["backbone"],
        layers=CONFIG["model"]["layers"],
        coreset_sampling_ratio=CONFIG["model"]["coreset_sampling_ratio"],
    )
    
    # 4. å¼•æ“
    engine = Engine(
        default_root_dir=CONFIG["engine"]["default_root_dir"],
        accelerator="auto",
        devices=1,
        max_epochs=CONFIG["engine"]["max_epochs"],
    )
    
    # 5. è®­ç»ƒ
    print("\n--- å¼€å§‹è®­ç»ƒ (Fitting) ---")
    engine.fit(model=model, datamodule=datamodule)
    
    print("\n--- å¼€å§‹æµ‹è¯• (Computing Metrics) ---")
    test_results = engine.test(model=model, datamodule=datamodule)
    
    # 7. é¢„æµ‹å¹¶ä¿å­˜å¯è§†åŒ–ç»“æœ
    print("\n--- æ­£åœ¨ç”Ÿæˆå¯è§†åŒ–ç»“æœ ---")
    test_img_path = data_root / "test" / "bad" / "0.png"
    predictions = engine.predict(model=model, data_path=test_img_path)
    
    # å¤„ç†é¢„æµ‹ç»“æœ
    if predictions:
        pred = predictions[0]
        score = pred["pred_score"]
        # å¦‚æœæ˜¯Tensoråˆ™è½¬float
        if hasattr(score, "item"): score = score.item()
            
        print(f"å›¾ç‰‡: {test_img_path}")
        print(f"å¼‚å¸¸å¾—åˆ†: {score:.4f} (è¶Šé«˜è¶Šå¼‚å¸¸)")

        print(f"å¯è§†åŒ–ç»“æœå·²ä¿å­˜è‡³: {CONFIG['engine']['default_root_dir']}")

if __name__ == "__main__":
    run_demo()

# import optuna
# from optuna.integration.pytorch_lightning import PyTorchLightningPruningCallback
# from torchmetrics import AUROC

# def run_hyperparameter_search():
#     # 1. å‡†å¤‡æ•°æ®ï¼ˆå¤ç”¨ä½ çš„prepare_dataï¼Œä»…è¿è¡Œ1æ¬¡ï¼‰
#     data_root = Path("./datasets/dummy_patchcore")
#     prepare_data(data_root)

#     # 2. å®šä¹‰è¶…å‚æ•°æœç´¢çš„ç›®æ ‡å‡½æ•°ï¼ˆæ ¸å¿ƒï¼šè¾“å…¥å‚æ•°ç»„åˆï¼Œè¾“å‡ºæ¨¡å‹æ•ˆæœæŒ‡æ ‡ï¼‰
#     def objective(trial: optuna.Trial):
#         # ã€å…³é”®ã€‘å®šä¹‰å¾…æœç´¢çš„è¶…å‚æ•°ç©ºé—´ï¼ˆå¯æ ¹æ®éœ€æ±‚æ‰©å±•ï¼‰
#         config = {
#             "model": {
#                 # å€™é€‰å€¼æœç´¢ï¼šbackboneä»æŒ‡å®šåˆ—è¡¨ä¸­é€‰
#                 "backbone": trial.suggest_categorical("backbone", ["resnet18", "resnet34"]),
#                 # å€™é€‰å€¼æœç´¢ï¼šlayersä»æŒ‡å®šåˆ—è¡¨ä¸­é€‰ï¼ˆPatchCoreç»å…¸ç»„åˆï¼‰
#                 "layers": trial.suggest_categorical("layers", [("layer1", "layer2"), ("layer1", "layer2", "layer3")]),
#                 # æ•°å€¼èŒƒå›´æœç´¢ï¼šcoreset_sampling_ratioä»0.1~0.5ä¸­é€‰ï¼Œæ­¥é•¿0.1
#                 "coreset_sampling_ratio": trial.suggest_float("coreset_sampling_ratio", 0.1, 0.5, step=0.1),
#             },
#             "dataset": {
#                 "image_size": (256, 256),  # å›ºå®šï¼Œæ— éœ€æœç´¢
#                 # æ•°å€¼å€™é€‰æœç´¢ï¼šbatch_sizeä»[4,8,16]ä¸­é€‰
#                 "train_batch_size": trial.suggest_categorical("train_batch_size", [4, 8, 16]),
#                 "eval_batch_size": trial.suggest_categorical("eval_batch_size", [4, 8, 16]),
#             },
#             "engine": {
#                 "max_epochs": 1,  # PatchCoreå›ºå®šä¸º1ï¼Œç»å¯¹ä¸æœç´¢
#                 "default_root_dir": f"./results_patchcore_trial_{trial.number}",  # æ¯ä¸ªè¯•éªŒå•ç‹¬ä¿å­˜ç»“æœ
#             }
#         }

#         # 3. é…ç½®æ•°æ®æ¨¡å—ï¼ˆä¸åŸä»£ç ä¸€è‡´ï¼Œä½¿ç”¨å½“å‰è¯•éªŒçš„å‚æ•°ï¼‰
#         datamodule = Folder(
#             name="dummy_patchcore",
#             root=data_root,
#             normal_dir="train/good",
#             abnormal_dir="test/bad",
#             normal_test_dir="test/good",
#             train_batch_size=config["dataset"]["train_batch_size"],
#             eval_batch_size=config["dataset"]["eval_batch_size"],
#             num_workers=8,
#         )
#         datamodule.setup()

#         # 4. åˆå§‹åŒ–æ¨¡å‹ï¼ˆä½¿ç”¨å½“å‰è¯•éªŒçš„å‚æ•°ï¼‰
#         model = Patchcore(
#             backbone=config["model"]["backbone"],
#             layers=config["model"]["layers"],
#             coreset_sampling_ratio=config["model"]["coreset_sampling_ratio"],
#         )

#         # 5. åˆå§‹åŒ–å¼•æ“
#         engine = Engine(
#             default_root_dir=config["engine"]["default_root_dir"],
#             accelerator="gpu",
#             max_epochs=config["engine"]["max_epochs"],
#         )

#         # 6. è®­ç»ƒ+æµ‹è¯•ï¼ˆè¿”å›æµ‹è¯•é›†æ ¸å¿ƒæŒ‡æ ‡ï¼šimage_AUROCï¼‰
#         engine.fit(model=model, datamodule=datamodule)
#         test_results = engine.test(model=model, datamodule=datamodule)
#         auroc_score = test_results[0]["image_AUROC"]  # å–å›¾åƒçº§AUROCä½œä¸ºä¼˜åŒ–ç›®æ ‡

#         # 7. è¿”å›æŒ‡æ ‡ï¼ˆOptunaä¼šæœ€å¤§åŒ–è¯¥å€¼ï¼Œæ‰¾åˆ°AUROCæœ€é«˜çš„å‚æ•°ç»„åˆï¼‰
#         return auroc_score

#     # 3. å¯åŠ¨è¶…å‚æ•°æœç´¢
#     print("===== å¼€å§‹PatchCoreè¶…å‚æ•°æœç´¢ =====")
#     # åˆ›å»ºç ”ç©¶å¯¹è±¡ï¼šä¼˜åŒ–ç›®æ ‡ä¸ºã€Œæœ€å¤§åŒ–AUROCã€ï¼Œå­˜å‚¨æœç´¢ç»“æœåˆ°æœ¬åœ°
#     study = optuna.create_study(
#         direction="maximize",  # æ ¸å¿ƒï¼šAUROCè¶Šå¤§æ•ˆæœè¶Šå¥½ï¼Œæ‰€ä»¥æœ€å¤§åŒ–
#         study_name="patchcore_anomaly_detection",
#         storage="sqlite:///patchcore_hpo.db",  # æœç´¢ç»“æœä¿å­˜åˆ°sqliteæ•°æ®åº“ï¼Œå¯åç»­æŸ¥çœ‹
#         load_if_exists=True,  # è‹¥æ•°æ®åº“å·²å­˜åœ¨ï¼ŒåŠ è½½åŸæœ‰ç»“æœï¼ˆé¿å…é‡å¤æœç´¢ï¼‰
#     )

#     # è¿è¡Œæœç´¢ï¼šæŒ‡å®šè¯•éªŒæ¬¡æ•°ï¼ˆå³å°è¯•å¤šå°‘ä¸ªå‚æ•°ç»„åˆï¼Œæ ¹æ®éœ€æ±‚è°ƒæ•´ï¼‰
#     study.optimize(
#         objective,
#         n_trials=3,  # å°è¯•3ä¸ªå‚æ•°ç»„åˆï¼Œå‚æ•°ç©ºé—´å¤§åˆ™å¢å¤§ï¼ˆå¦‚20/30ï¼‰
#         show_progress_bar=True,  # æ˜¾ç¤ºæœç´¢è¿›åº¦æ¡
#     )

#     # 4. è¾“å‡ºæœç´¢ç»“æœï¼ˆæ ¸å¿ƒï¼šæœ€ä¼˜å‚æ•°+æœ€ä¼˜æŒ‡æ ‡ï¼‰
#     print("\n===== è¶…å‚æ•°æœç´¢å®Œæˆ - æœ€ä¼˜ç»“æœ =====")
#     print(f"ğŸ† æœ€ä¼˜å›¾åƒçº§AUROC: {study.best_value:.4f}")
#     print(f"ğŸ”§ æœ€ä¼˜å‚æ•°ç»„åˆ: {study.best_params}")
#     print(f"ğŸ“Š æœ€ä¼˜è¯•éªŒç¼–å·: {study.best_trial.number}")

#     # å¯é€‰ï¼šæ‰“å°æ‰€æœ‰è¯•éªŒçš„è¯¦ç»†ç»“æœ
#     print("\n===== æ‰€æœ‰è¯•éªŒç»“æœæ±‡æ€» =====")
#     for trial in study.trials:
#         value_str = f"{trial.value:.4f}" if trial.value is not None else "N/A"
#         print(f"è¯•éªŒ{trial.number} | AUROC: {value_str} | å‚æ•°: {trial.params}")

#     # 5. ä½¿ç”¨æœ€ä¼˜å‚æ•°é‡æ–°è®­ç»ƒæœ€ç»ˆæ¨¡å‹ï¼ˆå¯é€‰ï¼Œå¾—åˆ°æœ€ä¼˜æ¨¡å‹ï¼‰
#     print("\n===== ä½¿ç”¨æœ€ä¼˜å‚æ•°è®­ç»ƒæœ€ç»ˆæ¨¡å‹ =====")
#     best_config = {
#         "model": {
#             "backbone": study.best_params["backbone"],
#             "layers": study.best_params["layers"],
#             "coreset_sampling_ratio": study.best_params["coreset_sampling_ratio"],
#         },
#         "dataset": {
#             "image_size": (256, 256),
#             "train_batch_size": study.best_params["train_batch_size"],
#             "eval_batch_size": study.best_params["eval_batch_size"],
#         },
#         "engine": {
#             "max_epochs": 1,
#             "default_root_dir": "./results_patchcore_best",
#         }
#     }

#     # ç”¨æœ€ä¼˜å‚æ•°åˆå§‹åŒ–ç»„ä»¶å¹¶è®­ç»ƒ
#     datamodule_best = Folder(
#         name="dummy_patchcore",
#         root=data_root,
#         normal_dir="train/good",
#         abnormal_dir="test/bad",
#         normal_test_dir="test/good",
#         train_batch_size=best_config["dataset"]["train_batch_size"],
#         eval_batch_size=best_config["dataset"]["eval_batch_size"],
#         num_workers=8,
#     )
#     datamodule_best.setup()

#     model_best = Patchcore(**best_config["model"])
#     engine_best = Engine(
#         default_root_dir=best_config["engine"]["default_root_dir"],
#         accelerator="gpu",
#         max_epochs=best_config["engine"]["max_epochs"],
#     )
#     engine_best.fit(model=model_best, datamodule=datamodule_best)

#     # ç”¨æœ€ä¼˜æ¨¡å‹é¢„æµ‹å•å¼ ç¼ºé™·å›¾
#     print("\n===== æœ€ä¼˜æ¨¡å‹å•å¼ ç¼ºé™·å›¾é¢„æµ‹ =====")
#     test_img_path = data_root / "test" / "bad" / "0.png"
#     predictions = engine_best.predict(model=model_best, data_path=test_img_path)
#     if predictions and len(predictions) > 0:
#         batch = predictions[0]
#         score = batch["pred_score"].item() if hasattr(batch["pred_score"], "item") else batch["pred_score"]
#         label = batch["pred_label"].item() if hasattr(batch["pred_label"], "item") else batch["pred_label"]
#         print(f">>> å›¾ç‰‡è·¯å¾„: {test_img_path}")
#         print(f">>> å¼‚å¸¸å¾—åˆ†: {score:.4f}")
#         print(f">>> é¢„æµ‹ç±»åˆ«: {'å¼‚å¸¸' if label else 'æ­£å¸¸'}")

# if __name__ == "__main__":
#     # æ›¿æ¢åŸæœ‰run_demoï¼Œå¯åŠ¨è¶…å‚æ•°æœç´¢
#     run_hyperparameter_search()
